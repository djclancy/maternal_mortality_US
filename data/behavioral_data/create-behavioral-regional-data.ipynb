{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Divisional & Regional Behavior Datasets\n",
    "This notebook will create a dataframe for each census division and region that contains behavioral data for the female population.The data contained includes the percentage of the female population who are obese, overweight, and report no physical activity as well as overall female population size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Existing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe containing the census division and region for each state\n",
    "census_divisions_df = pd.read_csv(\"data/census_divisions.csv\")\n",
    "\n",
    "# import dicitionary of dataframes containing the behavioral data for each state\n",
    "with open('data/state_behavior_data.pkl', 'rb') as file:\n",
    "    state_behavior_data = pickle.load(file)\n",
    "\n",
    "# import dataframe containing all the behavioral data for each state in a single dataframe    \n",
    "with open('data/all_states_behavior_data.pkl', 'rb') as file:\n",
    "    all_states_behavior_data = pickle.load(file)\n",
    "\n",
    "# import dictionary of dataframes containing female population numbers for each state between 2010 - 2023\n",
    "with open('data/population_by_state.pkl', 'rb') as file:\n",
    "    population_by_state = pickle.load(file)\n",
    "\n",
    "# import dictionary of dataframes containing ACS population data for each year between 2010 - 2023\n",
    "with open('data/population_dfs.pkl', 'rb') as file:\n",
    "    population_dfs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the weighted average for a subset of the data\n",
    "#       data: this is a pandas dataframe\n",
    "#       category1 & category2: these are the indicators for the subset of the data we want to select for\n",
    "#       category1_name & category2_name: these are the names of the columns that should be used to select for the subset of the data\n",
    "#       weight_column: this is the name of the column that should be used as weights for the average\n",
    "#       target_column: this is the name of the column that we want the weighted average of (we assume it consists of percentages)\n",
    "def compute_weighted_average(data, category1, category1_name, category2, category2_name, weight_column, target_column):\n",
    "    \n",
    "    # get the relevant data subset and drop any rows that contain empty values\n",
    "    subset_df = data[(data[category1_name] == category1) & (data[category2_name] == category2)].dropna(axis = 0, how = 'any')\n",
    "    #print(subset_df)\n",
    "    \n",
    "    # calculate the overall total; this will be used in the denominator when calculating the weighted average\n",
    "    total = subset_df[weight_column].sum()\n",
    "    #print(f\"total =\", total)\n",
    "\n",
    "    # calculate the numerator term in the weighted average\n",
    "    numerator = sum(subset_df[weight_column] * subset_df[target_column] / 100)\n",
    "    #print(f\"numerator =\", numerator)\n",
    "\n",
    "    # compute the weighted average\n",
    "    average = numerator / total * 100\n",
    "    return average, total\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File-Specific Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_divisions = [\"Division 1: New England\", \"Division 2: Middle Atlantic\", \"Division 3: East North Central\", \n",
    "                    \"Division 4: West North Central\", \"Division 5: South Atlantic\", \"Division 6: East South Central\",\n",
    "                    \"Division 7: West South Central\", \"Division 8: Mountain\", \"Division 9: Pacific\"]\n",
    "\n",
    "census_regions = [\"Region 1: Northeast\", \"Region 2: Midwest\", \"Region 3: South\", \"Region 4: West\"]\n",
    "\n",
    "census_divisions_dict = dict(zip(census_divisions, \n",
    "                                 ['Region 1: Northeast', 'Region 1: Northeast', 'Region 2: Midwest', 'Region 2: Midwest',\n",
    "                                  'Region 3: South', 'Region 3: South', 'Region 3: South', 'Region 4: West', 'Region 4: West']))\n",
    "\n",
    "column_names = ['Percent_Overweight', 'Percent_Obese', 'Percent_Overweight_or_Obese', 'Percent_No_Activity']\n",
    "\n",
    "# get years\n",
    "years = []\n",
    "for year in all_states_behavior_data['Year']:\n",
    "    if year not in years:\n",
    "        years.append(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Target Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "division_behavior_data = {}\n",
    "for division in census_divisions:\n",
    "    division_behavior_data[division] = pd.DataFrame({'Year': years,\n",
    "                                                    'Census Division': division,\n",
    "                                                    'Region': census_divisions_dict[division],\n",
    "                                                    'Female_Population': [None] * len(years),\n",
    "                                                    **{column: [None] * len(years) for column in column_names}})\n",
    "\n",
    "region_behavior_data = {}\n",
    "for region in census_regions:\n",
    "    region_behavior_data[region] = pd.DataFrame({'Year': years,\n",
    "                                                    'Region': region,\n",
    "                                                    'Female_Population': [None] * len(years),\n",
    "                                                    **{column: [None] * len(years) for column in column_names}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divisional data (in dictionary of dataframes format)\n",
    "for division in census_divisions:\n",
    "    for year in years:\n",
    "        for column in column_names:\n",
    "            average, total_population = compute_weighted_average(all_states_behavior_data, year, 'Year', division, 'Census Division', 'Female_Population', column)\n",
    "            division_behavior_data[division].loc[(division_behavior_data[division]['Year'] == year), column] = average\n",
    "        division_behavior_data[division].loc[(division_behavior_data[division]['Year'] == year), 'Female_Population'] = total_population\n",
    "\n",
    "# create a single dataframe that contains all the information in each divisional dataframe\n",
    "all_divisions_behavior_data = pd.concat(division_behavior_data.values(), ignore_index = True)\n",
    "\n",
    "# regional data (in dictionary of dataframes format)\n",
    "for region in census_regions:\n",
    "    for year in years:\n",
    "        for column in column_names:\n",
    "            average, total_population = compute_weighted_average(all_states_behavior_data, year, 'Year', region, 'Region', 'Female_Population', column)\n",
    "            region_behavior_data[region].loc[(region_behavior_data[region]['Year'] == year), column] = average\n",
    "        region_behavior_data[region].loc[(region_behavior_data[region]['Year'] == year), 'Female_Population'] = total_population  \n",
    "\n",
    "# create a single dataframe that contains all the information in each regional dataframe\n",
    "all_regions_behavior_data = pd.concat(region_behavior_data.values(), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store divisional data as csv files\n",
    "for division in division_behavior_data:\n",
    "    filepath = \"data/divisions/\" + re.sub(r'[ :]', '', division[8:].lower()) + \"_behavioral_data.csv\"\n",
    "    division_behavior_data[division].to_csv(filepath, index = False)\n",
    "all_divisions_behavior_data.to_csv(\"data/divisions/all_divisions_behavior_data.csv\", index = False)    \n",
    "\n",
    "# store the division behavioral dictionary of division dataframes\n",
    "with open('data/state_behavior_data.pkl', 'wb') as file:\n",
    "    pickle.dump(state_behavior_data, file)\n",
    "\n",
    "# store the dataframe containing all behavioral information for all divisions \n",
    "with open('data/all_divisions_behavior_data.pkl', 'wb') as file:\n",
    "    pickle.dump(all_divisions_behavior_data, file) \n",
    "\n",
    "# store regional data as csv files\n",
    "for region in region_behavior_data:\n",
    "    filepath = \"data/regions/\" + re.sub(r'[ :]', '', region[6:].lower()) + \"_behavioral_data.csv\"\n",
    "    region_behavior_data[region].to_csv(filepath, index = False)\n",
    "all_regions_behavior_data.to_csv(\"data/regions/all_regions_behavior_data.csv\", index = False)    \n",
    "\n",
    "# store the region behavioral dictionary of region dataframes\n",
    "with open('data/region_behavior_data.pkl', 'wb') as file:\n",
    "    pickle.dump(region_behavior_data, file)\n",
    "\n",
    "# store the dataframe containing all behavioral information for all regions \n",
    "with open('data/all_regions_behavior_data.pkl', 'wb') as file:\n",
    "    pickle.dump(all_regions_behavior_data, file)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
